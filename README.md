# AIâ€‘Predicted Eâ€‘Commerce ğŸ›’ğŸ¤–

![Made with](https://img.shields.io/badge/Made%20with-Python%203.8%2B-blue.svg)
![Framework](https://img.shields.io/badge/API-FastAPI-009688.svg)
![Model](https://img.shields.io/badge/Model-DistilBERT-8A2BE2.svg)
![Serving](https://img.shields.io/badge/Serving-Uvicorn-informational.svg)
![Cache](https://img.shields.io/badge/DB-Redis-red.svg)
![Docker](https://img.shields.io/badge/Container-Docker-blue.svg)

> An endâ€‘toâ€‘end **product categorization** service that predicts a predefined category from the product **name + description** using **NLP**. It includes data prep, training, an API, a minimal UI, and Docker Compose orchestration.

---

## ğŸ§­ Table of Contents
- [AIâ€‘Predicted Eâ€‘Commerce ğŸ›’ğŸ¤–](#aipredicted-ecommerce-)
  - [ğŸ§­ Table of Contents](#-table-of-contents)
  - [ğŸŒ Overview](#-overview)
  - [ğŸ—ºï¸ Workflow Diagram](#ï¸-workflow-diagram)
  - [âœ¨ Features](#-features)
  - [ğŸ§± Architecture](#-architecture)
  - [âœ… Project Plan \& Milestones](#-project-plan--milestones)
  - [âš¡ Quick Start](#-quick-start)
    - [With Docker (recommended)](#with-docker-recommended)
    - [Local Environment](#local-environment)
  - [ğŸ“¦ Dataset](#-dataset)
  - [ğŸ§  Training](#-training)
  - [ğŸ”Œ Inference \& API](#-inference--api)
  - [ğŸ–¥ï¸ Demo UI](#ï¸-demo-ui)
  - [ğŸ—„ï¸ Redis Persistence](#ï¸-redis-persistence)
  - [ğŸ—‚ï¸ Repository Structure](#ï¸-repository-structure)
  - [ğŸ“ˆ Metrics](#-metrics)
  - [ğŸ§¯ Troubleshooting](#-troubleshooting)
  - [ğŸ›£ï¸ Roadmap](#ï¸-roadmap)
  - [ğŸ“š References](#-references)
  - [ğŸ¤ Contributing](#-contributing)
  - [ğŸ“„ License](#-license)

---

## ğŸŒ Overview
This project trains and serves a **text classifier** for eâ€‘commerce. Given a product's **name** and **description**, it predicts the most likely **category**. The pipeline covers:

1) **Preprocessing** (cleaning, folding rare categories into `other`, `LabelEncoder`).  
2) **Training** a **DistilBERT** *sequence classification* model.  
3) **Serving** via **FastAPI** + **Uvicorn** (REST endpoints).  
4) **Lightweight storage** in **Redis** (SKU â†’ hash with name/description/category/predict).  
5) A minimal **HTML UI** for demos.  
6) **Jupyter** for EDA and experiments.  
7) **Docker Compose** for a reproducible local stack.

---

## ğŸ—ºï¸ Workflow Diagram

<p align="center">
  <img src="assets/ai_ecommerce_workflow_demo.gif" alt="AI E-Commerce Workflow" width="900">
</p>

---

## âœ¨ Features
- ğŸ”¤ **Transformers NLP**: fineâ€‘tuned **DistilBERT** for multiâ€‘class classification.  
- ğŸ§¹ **Reproducible preprocessing**: `text = name + description`, NA filling, `LabelEncoder`.  
- ğŸš€ **FastAPI** with automatic docs at `/docs`.  
- ğŸ’¾ **Redis** as a fast keyâ€‘value store for items.  
- ğŸ§ª **Notebooks** for EDA/experimentation.  
- ğŸ³ **Docker Compose**: API, Redis and Jupyter on a shared network.  

---

## ğŸ§± Architecture
- **`src/preprocessdata.py`**: reads BestBuy JSON, cleans, filters infrequent categories (â‰¥ 100), builds `text`, fits `LabelEncoder`, saves `data.csv`, `label.csv`, `label_encoder.pkl`.
- **`src/train.py`**: tokenization (**DistilBERT**, `max_length=18`), *fineâ€‘tuning* (`epochs=3`, `lr=5eâ€‘5`, `batch_size=16`), evaluation, and persists model/tokenizer in `models/`.
- **`src/predict.py`**: loads artifacts and exposes `main_predict(name, description)` returning the **category id**.
- **`app.py` (FastAPI)**: REST endpoints + serverâ€‘side templates.  
- **`templates/`**: simple HTML for the demo form.  
- **`models/`**: artifacts (`classifier/`, `tokenizer/`, `encoder/`).  
- **`docker-compose.yml` + `docker/`**: reproducible local deployment.  

---

## âœ… Project Plan & Milestones
The project follows this **11â€‘step milestone plan** (adapted to this implementation):

1. **Setup repository & structure** ğŸ§©  
   - Initialize the GitHub repo, create subâ€‘folders, and scaffold deliverables.  
   - Optionally, prepare an **AWS** EC2 instance/S3 bucket for dataset evaluation and storage.

2. **Download & evaluate the dataset (EDA)** ğŸ”  
   - Compute **#products**, **#unique categories**, histograms, top categories.  
   - Note: a product can belong to **multiple categories** (taxonomy). We take the **last** (most specific) one.  
   - Keep categories with **â‰¥ 100** samples; map the rest to **`other`**.

3. **Create a training dataset** ğŸ§½  
   - Implement a cleaning function for the text: remove **nonâ€‘alphabetical chars**, **punctuation**, and optionally **stop words**; normalize whitespace/casing.  
   - Build `text = name + " " + description`.  
   - (Optional) Persist the cleaned dataset to **S3** (text + final category).  
   - This repo saves `data.csv` / `label.csv` and a `LabelEncoder` locally under `./data/` and `./models/`.

4. **Stateâ€‘ofâ€‘theâ€‘art review** ğŸ“š  
   - Compare **tokenization** approaches (WordPiece/BPE), **word embeddings**, and **TFâ€‘IDF**.  
   - Consider alternative **classifiers**: **LightGBM**, **XGBoost**, **CatBoost**, **RandomForest**, **Ensembles/Stacking**, plus an **MLP** baseline.

5. **Classifier & accuracy research** ğŸ§ª  
   - Train/evaluate the selected classical models (and an MLP) on the cleaned features.  
   - In this implementation, we prioritize a **Transformer baseline (DistilBERT)** for strong text performance.

6. **Evaluate/test the initial classifier** ğŸ“Š  
   - Compare **accuracy**, **AUC**, **training time**, and **inference time** across candidates.  
   - Select the **best model** balancing quality and latency. (This repo reports ~0.91 accuracy/F1 with DistilBERT.)

7. **Setup an API for product classification** ğŸŒ  
   - Expose the model through **FastAPI**. Prefer containerization with **Docker** for reproducibility and portability.

8. **Integrate a basic UI & secure the API** ğŸ–¥ï¸ğŸ”  
   - Provide a simple web form for demos (this repo includes `templates/`).  
   - Security hardening ideas: **CORS** rules, **rate limiting**, **auth (e.g., JWT)**, secrets in **env vars**, and **HTTPS** behind a reverse proxy.

9. **Fineâ€‘tune / Train additional models** ğŸ¯  
   - After the first evaluation, iterate to improve accuracy/latency (hyperparameters, longer context, better cleaning, class weights, focal loss, etc.).

9.5 **Add API tests (optional)** ğŸ§ª  
   - Unit/integration tests for endpoints and a small smokeâ€‘test for inference.

10. **Preview to other teams** ğŸ“£  
   - Demo the service and gather feedback for final adjustments (UX, latency, error messages).

11. **Build final presentation** ğŸ§¾  
   - Prepare slides/live demo for *Demo Day*. Document reproducibility and limitations.

> The milestones above are **highâ€‘level** and should be refined into smaller tasks as you learn more about the dataset and constraints.

---

## âš¡ Quick Start

### With Docker (recommended)
1. Clone the repo and `cd` to the root (where `docker-compose.yml` lives).  
2. (Optional) Ensure **Git LFS** if you need `*.safetensors`:
   ```bash
   git lfs install
   git lfs pull
   ```
3. Bring the stack up:
   ```bash
   sudo docker-compose up
   ```
4. Open:
   - API: `http://0.0.0.0:8080/` (docs at `http://0.0.0.0:8080/docs`)
   - Jupyter: `http://localhost:8888/`

### Local Environment
> The project is optimized for Docker. If running locally:
- Start **Redis** on `localhost:6379` or change the `host` in `app.py` (defaults to `redis`, the Docker service name).  
- Install deps and launch:
  ```bash
  pip install -r requirements.txt
  uvicorn app:app --reload --port 8080
  ```

---

## ğŸ“¦ Dataset
- Based on the open **BestBuy** eâ€‘commerce dataset used in the AnyoneAI challenge.  
- Two source files are relevant: `categories.json` and `products.json`.  
- Raw GitHub (example):  
  ```
  https://raw.githubusercontent.com/anyoneai/e-commerce-open-data-set/master/products.json
  ```

**Single product example:**
```json
{
  "sku": 1004695,
  "name": "GoPro - Camera Mount Accessory Kit - Black",
  "type": "HardGood",
  "price": 19.99,
  "upc": "185323000309",
  "category": [
    {"id": "abcat0400000", "name": "Cameras & Camcorders"},
    {"id": "abcat0410022", "name": "Camcorder Accessories"},
    {"id": "pcmcat329700050009", "name": "Action Camcorder Accessories"},
    {"id": "pcmcat240500050057", "name": "Action Camcorder Mounts"},
    {"id": "pcmcat329700050020", "name": "Handlebar/Seatpost Mounts"}
  ],
  "shipping": 5.49,
  "description": "Compatible with most GoPro cameras; includes a variety of camera mounting accessories",
  "manufacturer": "GoPro",
  "model": "AGBAG-001",
  "url": "http://www.bestbuy.com/site/gopro-camera-mount-accessory-kit-black/1004695.p?id=1218249514954&skuId=1004695&cmp=RMXCC",
  "image": "http://img.bbystatic.com/BestBuy_US/images/products/1004/1004695_rc.jpg"
}
```
> Realâ€‘world descriptions can be **short or lowâ€‘quality**. The model should be robust to sparse text.

This repo expects `./data/raw/products.json.gz`. During preprocessing we take the **last** category in the list (most specific) and fold categories with **< 100** samples into **"other"**.

---

## ğŸ§  Training
1. **Preprocess**  
   ```python
   from src.preprocessdata import main_preprocessdata
   main_preprocessdata()
   # Produces data.csv, label.csv and label_encoder.pkl
   ```
2. **Train**  
   ```python
   from src.train import main_train
   main_train()
   # Saves model and tokenizer under ./models/
   ```
3. **Artifacts**  
   - `models/classifier/model.safetensors`  
   - `models/tokenizer/*`  
   - `models/encoder/label_encoder.pkl`

> You can run these steps inside the **Jupyter** container for full reproducibility.

---

## ğŸ”Œ Inference & API
**Key FastAPI endpoints**
- `GET /predict_category?name=...&description=...` â†’ returns the category id.  
- `POST /create_item` â†’ stores an item in Redis with `sku`, `name`, `description`, `category`.  
- `GET /get_item?sku=...` â†’ retrieves the hash for a SKU.  
- `PUT /update_predict_category?sku=...` â†’ runs the model and writes `predict_category` to Redis.

Interactive docs: `http://0.0.0.0:8080/docs`

**Security hardening (suggested):**
- CORS policy, API key/JWT, rate limiting, request validation, secrets via env vars, HTTPS behind a reverse proxy (e.g., Nginx/Caddy).

---

## ğŸ–¥ï¸ Demo UI
- `GET /` renders `templates/form.html` (simple form).  
- **POST** to `/new_item_and_predict/` creates a random SKU, runs inference and shows `templates/result.html` with the **predicted category**.

> If you build your own frontend, submit `name` and `description` to `/predict_category` or reuse the form flow.

---

## ğŸ—„ï¸ Redis Persistence
- **Key**: `sku`  
- **Hash fields**: `name`, `description`, `category`, `predict_category`  
- The API already includes **create**, **read**, and **update** flows.

---

## ğŸ—‚ï¸ Repository Structure
```text
.
â”œâ”€ app.py
â”œâ”€ docker-compose.yml
â”œâ”€ docker/
â”‚  â”œâ”€ api
â”‚  â””â”€ jupyter
â”œâ”€ models/
â”‚  â”œâ”€ classifier/
â”‚  â”œâ”€ encoder/
â”‚  â””â”€ tokenizer/
â”œâ”€ notebooks/
â”œâ”€ src/
â”‚  â”œâ”€ preprocessdata.py
â”‚  â”œâ”€ train.py
â”‚  â”œâ”€ predict.py
â”‚  â””â”€ settings.py
â”œâ”€ templates/
â”‚  â”œâ”€ form.html
â”‚  â””â”€ result.html
â””â”€ assets/
   â”œâ”€ ai_ecommerce_workflow_v2.svg
   â””â”€ ai_ecommerce_workflow_v2.png
```

---

## ğŸ“ˆ Metrics
*Reported on validation/test after the reference training:*

| Split       | mean_accuracy | f1 weighted | f1 micro | f1 macro |
|-------------|---------------|-------------|----------|----------|
| Validation  | 0.9109        | 0.9113      | 0.9108   | 0.8697   |
| Test        | 0.9112        | 0.9105      | 0.9111   | 0.8670   |

> Results may vary if you change *max_length*, *epochs*, the category threshold, etc.

---

## ğŸ§¯ Troubleshooting
- **Model won't load** â†’ Ensure `git lfs install && git lfs pull` to fetch `model.safetensors`.  
- **`/new_item_and_predict/` fails** â†’ It must be a **POST** with **form-data** (not JSON).  
- **Redis unreachable** â†’ Confirm the `redis` container is running (`docker ps`) or adjust the `host` in `app.py` when running without Docker.  
- **Dataset missing** â†’ Place `products.json.gz` under `./data/raw/`.

---

## ğŸ›£ï¸ Roadmap
- [ ] API tests (pytest).  
- [ ] Improved text cleaning (stopwords, normalization).  
- [ ] Additional metrics (perâ€‘class confusion matrix, **AUC**).  
- [ ] Fineâ€‘tuning with *class weights*/*focal loss* for imbalance.  
- [ ] Batch prediction endpoint.  
- [ ] Optional S3 integration for cleaned datasets and artifacts.

---

## ğŸ“š References
- **Large Scale Product Categorization using Structured and Unstructured Attributes** â€” Abhinandan Krishnan, Abilash Amarthaluri.  
- **Multiâ€‘Label Product Categorization Using Multiâ€‘Modal Fusion Models** â€” Pasawee Wirojwatanakul, Artit Wangperawong.

---

## ğŸ¤ Contributing
PRs and suggestions are welcome! Please open an issue to discuss major changes. Style: *black/flake8* recommended.

---

## ğŸ“„ License
This project is distributed under the terms listed in `LICENSE`.
